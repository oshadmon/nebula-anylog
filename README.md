# Overlay Networks

AnyLog uses overlay networks in order to have nodes that are distributed on separated subnetworks to act as if they're all
under the same network. For demonstration purposes we use Nebula, an open-source overlay network developed by the _Slack_ 
team and managed under [Defined](https://www.defined.net/). 

_Nebula_ is a mutually authenticated peer-to-peer overlay network, based on [Noise Protocol Framework](https://noiseprotocol.org/). 
This means that Nebula's overlay network uses certificates to assert a node's IP address, name, and membership within user-defined groups. 

**Documentation**
* [GitHub](https://github.com/slackhq/nebula)
* [Documentation](https://nebula.defined.net/docs)
* [Defines' Website](https://www.defined.net/)
* [Configuring Overlay with AnyLog](Configuring%20Overlay%20with%20AnyLog.md)

## Terminology 
_Nebula's_ overlay network requires a minimum of 2 nodes: _lighthouse_ and regular nodes, nicknamed _host_, as well as 
authentication certificates for the nodes to be associated with one another.  

* **Lighthouse**: A _Nebula_ host that is responsible for keeping track of other Nebula hosts, and helping them find each 
other within a Nebula network. In order to eliminate centralization, Nebula offers advanced configuration to support 
[multiple lighthouses](https://www.defined.net/blog/newsletter-admin-api-cert-rotation-multiple-lighthouses/#support-for-multiple-lighthouses).

* **Host**: A _Nebula_ host is simply any single node in the network, e.g. a server, laptop, phone, tablet. Each host will 
have its own private key, which is used to validate the identity of that host when Nebula tunnels are created.

* **Certificate Authority**: Nebula Certificate Authority (CA) consists of two files, a CA certificate, and an associated 
private key. CA certificate is distributed to, and trusted by, every host on the network. The CA private key should not be 
distributed, and can be kept offline when not being used to add hosts to a Nebula network.

## Deploying an Overlay 

### Preparing Machines
The following is to be done on both machines 
1. Clone nebula-overlay

```shell
cd $HOME/
git clone https://github.com/oshadmon/nebula-anylog
```

2. Create directory: `/var/bin/nebula/configs`
```shell
sudo mkdir -p /var/bin/nebula/configs
sudo chown -R root:root /var/bin/nebula
sudo chmod -R 755 /var/bin/nebula
```

3. (Optional) In `/var/bin/nebula/configs`, add credential and key files that you're going to use. The following sections 
will provide more details about how to create keys 

**Lighthouse**

| File | Purpose |                                      Created When                                       |
| :---: | :---: |:---------------------------------------------------------------------------------------:|
| ca.crt, ca.key | root certificates | automatically created when deploying lighthouse if not found in /var/bin/nebula/configs |
| lighthouse.crt, lighthouse.key | Node certificate for lighthouse |             automatically created when deploying lighthouse if not found in             |
| node.yml | Runtime configuration file |   automatically created based on [nebula_configs.env](nebula_configs.env) file    | autogenerated | 

**Host**: 

|        File        | Purpose | Created When |
|:------------------:| :---: | :---: |
|       ca.crt       | CA certificate used to sign node certificates | should be created with lighthouse and copied to all hosts |
| host.crt, host.key | Required for signing host certs | created in lighthouse and copied into host instance(s)  |    
|      node.yml      | Runtime configuration file | automatically created based on [nebula_configs.env](nebula_configs.env) file | autogenerated | 


### Lighthouse
0. cd into `nebula-anylog` directory 
```shell
cd $HOME/nebula-anylog
```

1. Update [nebula_configs.env](nebula_configs.env) with the desired IPs
```shell
# whether nebula instance is lighthouse
IS_LIGHTHOUSE=true

# CIDR IP
CIDR_OVERLAY_ADDRESS=10.10.1.1/24

# actual IP
LIGHTHOUSE_IP=10.10.1.1

# Lighthouse physical IP
LIGHTHOUSE_NODE_IP=10.0.0.169

# Nebula IP address for the node
OVERLAY_IP=10.10.1.1
```

2. Start Nebula 
```shell
docker compose -f docker-compose.yml up -d
```

3. To test simply do `ifconfig` 
```shell
root@localhost:~# ifconfig nebula1
nebula1: flags=4305<UP,POINTOPOINT,RUNNING,NOARP,MULTICAST>  mtu 1300
        inet 10.10.1.1  netmask 255.255.255.0  destination 10.10.1.1
        inet6 fe80::2e3:3023:c3d4:6c6c  prefixlen 64  scopeid 0x20<link>
        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 500  (UNSPEC)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 21  bytes 1008 (1.0 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```


### Host 

The following steps are done on the **lighthouse** node

1. Attach to the lighthouse docker instance 
```shell
docker attach --detach-keys=ctrl-d nebula
```

2. Make sure you're in - /app/nebula
```shell
root@localhost:/app/nebula# pwd 
/app/nebula

# if not 
cd /app/nebula 
```

3. Create host keys 
```shell
./nebula-cert sign -name "host" -ip "${CIDR_OVERLAY_ADDRESS}" \
      -ca-key "$ANYLOG_PATH/nebula/ca.key" \
      -ca-crt "$ANYLOG_PATH/nebula/ca.crt" \
      -out-crt "$ANYLOG_PATH/nebula/configs/host.crt" \
      -out-key "$ANYLOG_PATH/nebula/configs/host.key" \
      -groups "anylog-node" 
```

4. To validate 
```shell
root@localhost:/app/nebula# ls -l /app/nebula/configs/
total 24
-rw------- 1 root root 243 Nov  7 03:22 ca.crt
-rw------- 1 root root 174 Nov  7 03:22 ca.key
-rw------- 1 root root 312 Nov  7 16:29 host.crt
-rw------- 1 root root 127 Nov  7 16:29 host.key
-rw------- 1 root root 300 Nov  7 03:22 lighthouse.crt
-rw------- 1 root root 127 Nov  7 03:22 lighthouse.key
```

The following steps are done on the **host** node

1. Make sure the machine is prepared to run a Nebula overlay - directions can be found [here](#preparing-machines)

2. Copy the following keys from lighthouse (outside docker `/var/bin/nebula/configs`) into host directory `/var/bin/nebula/configs`
* ca.crt 
* host.crt 
* host.key 

3. Update [nebula_configs.env](nebula_configs.env) with the desired IPs
```shell
# whether nebula instance is lighthouse
IS_LIGHTHOUSE=false

# CIDR IP
CIDR_OVERLAY_ADDRESS=10.10.1.2/24

# actual IP
LIGHTHOUSE_IP=10.10.1.1

# Lighthouse physical IP
LIGHTHOUSE_NODE_IP=10.0.0.169

# Nebula IP address for the node
OVERLAY_IP=10.10.1.2
```

4. Start Nebula 
```shell
docker compose -f docker-compose.yml up -
```

5. To test simply do `ifconfig` 
```shell
root@localhost:~# ifconfig nebula1
nebula1: flags=4305<UP,POINTOPOINT,RUNNING,NOARP,MULTICAST>  mtu 1300
        inet 10.10.1.2  netmask 255.255.255.0  destination 10.10.1.2
        inet6 fe80::2e3:3023:c3d4:6c6c  prefixlen 64  scopeid 0x20<link>
        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 500  (UNSPEC)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 21  bytes 1008 (1.0 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```